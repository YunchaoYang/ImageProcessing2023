
ml purge
ml ngc-pytorch/1.11.0

[@c0304a-s2 pytorch]$ time python pytorch-multigpu.py --num-gpus 1
INFO:    underlay of /etc/localtime required more than 50 (94) bind mounts
INFO:    underlay of /usr/bin/nvidia-cuda-mps-control required more than 50 (470) bind mounts

=============
== PyTorch ==
=============

NVIDIA Release 21.12 (build 29870972)
PyTorch Version 1.11.0a0+b6df043

Container image Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2021 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

NVIDIA Deep Learning Profiler (dlprof) Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
170499072it [00:04, 35399506.69it/s]
Extracting ./data/cifar-10-python.tar.gz to ./data
Files already downloaded and verified
WideResNet(
  (input_block): cbrblock(
    (cbr): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (block1): conv_block(
    (scale): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), padding=same)
    (layer1): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (dropout): Dropout(p=0.01, inplace=False)
    (layer2): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (block2): conv_block(
    (layer1): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (dropout): Dropout(p=0.01, inplace=False)
    (layer2): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (block3): conv_block(
    (scale): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), padding=same)
    (layer1): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (dropout): Dropout(p=0.01, inplace=False)
    (layer2): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (block4): conv_block(
    (layer1): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (dropout): Dropout(p=0.01, inplace=False)
    (layer2): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (block5): conv_block(
    (scale): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), padding=same)
    (layer1): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (dropout): Dropout(p=0.01, inplace=False)
    (layer2): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (block6): conv_block(
    (layer1): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (dropout): Dropout(p=0.01, inplace=False)
    (layer2): cbrblock(
      (cbr): Sequential(
        (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (pool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (flat): Flatten(start_dim=1, end_dim=-1)
  (fc): Linear(in_features=640, out_features=10, bias=True)
)

 Total # of parameters:  17117754

Epoch =  1: Cumulative Time = 52.251, Epoch Time = 52.251, Images/sec = 956.6157836914062, Training Accuracy = 0.495, Validation Loss = 1.022, Validation Accuracy = 0.632
Epoch =  2: Cumulative Time = 99.555, Epoch Time = 47.304, Images/sec = 1056.657470703125, Training Accuracy = 0.685, Validation Loss = 0.718, Validation Accuracy = 0.757
Epoch =  3: Cumulative Time = 146.847, Epoch Time = 47.293, Images/sec = 1056.907958984375, Training Accuracy = 0.745, Validation Loss = 0.563, Validation Accuracy = 0.807
Epoch =  4: Cumulative Time = 194.154, Epoch Time = 47.307, Images/sec = 1056.59130859375, Training Accuracy = 0.777, Validation Loss = 0.530, Validation Accuracy = 0.822
Epoch =  5: Cumulative Time = 241.456, Epoch Time = 47.302, Images/sec = 1056.708740234375, Training Accuracy = 0.801, Validation Loss = 0.564, Validation Accuracy = 0.816
Epoch =  6: Cumulative Time = 288.749, Epoch Time = 47.293, Images/sec = 1056.9052734375, Training Accuracy = 0.819, Validation Loss = 0.457, Validation Accuracy = 0.846
Epoch =  7: Cumulative Time = 336.039, Epoch Time = 47.290, Images/sec = 1056.9639892578125, Training Accuracy = 0.834, Validation Loss = 0.395, Validation Accuracy = 0.866
Epoch =  8: Cumulative Time = 383.308, Epoch Time = 47.269, Images/sec = 1057.4306640625, Training Accuracy = 0.846, Validation Loss = 0.382, Validation Accuracy = 0.868
Early stopping after epoch 8

real    7m10.690s
user    7m13.273s
sys     0m38.198s

